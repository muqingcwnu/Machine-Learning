{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956a2c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2 \n",
      "\n",
      "1) Filter Method: Feature selection based on correlation with target\n",
      "             Feature  AbsCorrelation\n",
      "3   petal width (cm)        0.956547\n",
      "2  petal length (cm)        0.949035\n",
      "0  sepal length (cm)        0.782561\n",
      "1   sepal width (cm)        0.426658\n",
      "Selected features by filter method: ['petal width (cm)', 'petal length (cm)', 'sepal length (cm)'] \n",
      "\n",
      "2) Wrapper Method: Recursive Feature Elimination (RFE) with Logistic Regression\n",
      "sepal length (cm): Not Selected\n",
      "sepal width (cm): Not Selected\n",
      "petal length (cm): Selected\n",
      "petal width (cm): Selected\n",
      "Selected features by wrapper method: ['petal length (cm)', 'petal width (cm)'] \n",
      "\n",
      "3) Embedded Method: Feature importance using Random Forest\n",
      "             Feature  Importance\n",
      "3   petal width (cm)    0.469902\n",
      "2  petal length (cm)    0.415278\n",
      "0  sepal length (cm)    0.096623\n",
      "1   sepal width (cm)    0.018198\n",
      "Selected features by embedded method: ['petal width (cm)', 'petal length (cm)'] \n",
      "\n",
      "Summary of selected features:\n",
      "Filter method: ['petal width (cm)', 'petal length (cm)', 'sepal length (cm)']\n",
      "Wrapper method: ['petal length (cm)', 'petal width (cm)']\n",
      "Embedded method: ['petal width (cm)', 'petal length (cm)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load Iris dataset into a DataFrame\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "print(\"Original Features:\\n\", X.head(), \"\\n\")\n",
    "\n",
    "# -------- 1) FILTER METHOD: Select features by correlation threshold --------\n",
    "print(\"1) Filter Method: Feature selection based on correlation with target\")\n",
    "\n",
    "# Calculate absolute correlation of each feature with target\n",
    "correlations = []\n",
    "for col in X.columns:\n",
    "    corr = np.corrcoef(X[col], y)[0, 1]  # Pearson correlation\n",
    "    correlations.append(abs(corr))\n",
    "\n",
    "# Create DataFrame of correlations\n",
    "corr_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'AbsCorrelation': correlations\n",
    "}).sort_values(by='AbsCorrelation', ascending=False)\n",
    "\n",
    "print(corr_df)\n",
    "\n",
    "# Select features with absolute correlation > 0.5 (you can change threshold)\n",
    "selected_features = corr_df[corr_df['AbsCorrelation'] > 0.5]['Feature'].tolist()\n",
    "print(\"Selected features by filter method:\", selected_features, \"\\n\")\n",
    "\n",
    "X_filtered = X[selected_features]\n",
    "\n",
    "# -------- 2) WRAPPER METHOD: Recursive Feature Elimination (RFE) --------\n",
    "print(\"2) Wrapper Method: Recursive Feature Elimination (RFE) with Logistic Regression\")\n",
    "\n",
    "model = LogisticRegression(max_iter=500)\n",
    "# RFE to select top 2 features\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Print which features were selected\n",
    "for i in range(X.shape[1]):\n",
    "    print(f\"{X.columns[i]}: {'Selected' if rfe.support_[i] else 'Not Selected'}\")\n",
    "\n",
    "X_rfe = X.loc[:, rfe.support_]\n",
    "print(\"Selected features by wrapper method:\", X_rfe.columns.tolist(), \"\\n\")\n",
    "\n",
    "# -------- 3) EMBEDDED METHOD: Feature importance from Random Forest --------\n",
    "print(\"3) Embedded Method: Feature importance using Random Forest\")\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Select features with importance above the mean importance\n",
    "mean_importance = importances.mean()\n",
    "selected_rf = feature_importance_df[feature_importance_df['Importance'] > mean_importance]['Feature'].tolist()\n",
    "print(\"Selected features by embedded method:\", selected_rf, \"\\n\")\n",
    "\n",
    "X_rf_selected = X[selected_rf]\n",
    "\n",
    "# -------- Summary of selected features --------\n",
    "print(\"Summary of selected features:\")\n",
    "print(f\"Filter method: {selected_features}\")\n",
    "print(f\"Wrapper method: {X_rfe.columns.tolist()}\")\n",
    "print(f\"Embedded method: {selected_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc90d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Iris features:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2 \n",
      "\n",
      "1) Filter Method: Chi-Square Test\n",
      "Selected features by Chi-Square: ['petal length (cm)', 'petal width (cm)'] \n",
      "\n",
      "2) Filter Method: Variance Threshold\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (50) does not match length of index (150)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Add a low variance column for demonstration\u001b[39;00m\n\u001b[0;32m     33\u001b[0m X_var \u001b[38;5;241m=\u001b[39m X_iris\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 34\u001b[0m \u001b[43mX_var\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlow_variance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     36\u001b[0m selector \u001b[38;5;241m=\u001b[39m VarianceThreshold(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)  \u001b[38;5;66;03m# remove zero variance\u001b[39;00m\n\u001b[0;32m     37\u001b[0m X_var_reduced \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mfit_transform(X_var)\n",
      "File \u001b[1;32mc:\\Users\\parve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\parve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\parve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\parve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (50) does not match length of index (150)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, make_regression\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, RFE, SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# -------- Load datasets --------\n",
    "iris = load_iris()\n",
    "X_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y_iris = iris.target\n",
    "\n",
    "X_reg, y_reg = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)\n",
    "\n",
    "print(\"Original Iris features:\\n\", X_iris.head(), \"\\n\")\n",
    "\n",
    "# -------- 1) Filter: Chi-Square Test (for classification with discretized features) --------\n",
    "print(\"1) Filter Method: Chi-Square Test\")\n",
    "\n",
    "# Discretize numeric features for chi2\n",
    "X_discrete = X_iris.apply(lambda x: pd.cut(x, bins=10, labels=False))\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "X_chi2 = chi2_selector.fit_transform(X_discrete, y_iris)\n",
    "\n",
    "selected_chi2 = X_iris.columns[chi2_selector.get_support()]\n",
    "print(\"Selected features by Chi-Square:\", selected_chi2.tolist(), \"\\n\")\n",
    "\n",
    "# -------- 2) Filter: Variance Threshold (remove low variance features) --------\n",
    "print(\"2) Filter Method: Variance Threshold\")\n",
    "\n",
    "# Add a low variance (constant) column for demonstration\n",
    "X_var = X_iris.copy()\n",
    "X_var['low_variance'] = 1  # Constant column same value for all rows\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.0)  # remove zero-variance columns\n",
    "X_var_reduced = selector.fit_transform(X_var)\n",
    "\n",
    "print(\"Original features shape:\", X_var.shape)\n",
    "print(\"Reduced features shape after VarianceThreshold:\", X_var_reduced.shape, \"\\n\")\n",
    "\n",
    "# -------- 3) Wrapper: Recursive Feature Elimination (RFE) --------\n",
    "print(\"3) Wrapper Method: RFE with Logistic Regression\")\n",
    "\n",
    "model = LogisticRegression(max_iter=500)\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "rfe.fit(X_iris, y_iris)\n",
    "\n",
    "selected_rfe = X_iris.columns[rfe.support_]\n",
    "print(\"Selected features by RFE:\", selected_rfe.tolist(), \"\\n\")\n",
    "\n",
    "# -------- 4) Embedded: Lasso for regression --------\n",
    "print(\"4) Embedded Method: Lasso for regression feature selection\")\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_reg, y_reg)\n",
    "\n",
    "selected_lasso = np.array(range(X_reg.shape[1]))[lasso.coef_ != 0]\n",
    "print(\"Selected features by Lasso:\", selected_lasso.tolist(), \"\\n\")\n",
    "\n",
    "# -------- Bonus: Sequential Feature Selector --------\n",
    "print(\"Bonus) Wrapper: Sequential Forward Selection with KNN\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=2, direction='forward')\n",
    "sfs.fit(X_iris, y_iris)\n",
    "\n",
    "selected_sfs = X_iris.columns[sfs.get_support()]\n",
    "print(\"Selected features by Sequential Forward Selection:\", selected_sfs.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7766143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
